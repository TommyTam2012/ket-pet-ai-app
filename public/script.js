// script.js - now with dynamic exam switching + multilingual TTS

console.log("ğŸŸ¢ script.js loaded successfully");

const responseBox = document.getElementById("responseBox");
const questionInput = document.getElementById("questionInput");
const historyList = document.getElementById("historyList");
const micBtn = document.getElementById("micBtn");

const translationBox = document.createElement("div");
translationBox.id = "chineseTranslation";
translationBox.style.marginTop = "10px";
translationBox.style.fontSize = "0.95em";
translationBox.style.color = "#333";
responseBox.insertAdjacentElement("afterend", translationBox);

// ğŸ§­ Default exam
let currentExamId = "ket01";

// ğŸ§  Dynamically switch exam set
function setExam(examId) {
  currentExamId = examId;

  const folder = examId.startsWith("pet") ? "pet" : "KET";
  const pdfUrl = `/exams/${folder}/${examId}.pdf`;
  window.open(pdfUrl, "_blank");

  console.log(`ğŸ“˜ Exam set to ${examId}`);
}

function submitQuestion() {
  console.log("ğŸ”¥ submitQuestion triggered!");

  const question = questionInput.value.trim();
  if (!question || !currentExamId) {
    alert("âš ï¸ è¯·å…ˆé€‰æ‹©è¯•å·å¹¶è¾“å…¥é—®é¢˜ã€‚");
    return;
  }

  responseBox.textContent = "æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™...";
  translationBox.textContent = "";

  const examFolder = currentExamId.startsWith("pet") ? "pet" : "KET";

  const imageMessages = [
    { type: "text", text: question }
  ];

  for (let i = 1; i <= 13; i++) {
    const imageUrl = `/exams/${examFolder}/${currentExamId}_page${i}.png`;
    imageMessages.push({
      type: "image_url",
      image_url: { url: window.location.origin + imageUrl }
    });
  }

  fetch("/api/analyze", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ prompt: question, messages: imageMessages })
  })
    .then(async res => {
      const text = await res.text();
      try {
        return JSON.parse(text);
      } catch (err) {
        console.error("âŒ Server returned non-JSON:", text);
        throw new Error("æœåŠ¡å™¨è¿”å›é JSON å†…å®¹");
      }
    })
    .then(data => {
      const answer = data.response || "æ— æ³•è·å–è‹±æ–‡å›ç­”ã€‚";
      const translated = data.translated || "æ— æ³•è·å–ä¸­æ–‡ç¿»è¯‘ã€‚";

      responseBox.textContent = answer;
      translationBox.textContent = `ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š${translated}`;

      addToHistory(question, `${answer}<br><em>ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š</em>${translated}`);
    })
    .catch(err => {
      responseBox.textContent = "å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚";
      console.error("âŒ GPT error:", err);
    });

  questionInput.value = "";
}

function addToHistory(question, answer) {
  const li = document.createElement("li");
  li.innerHTML = `<strong>é—®ï¼š</strong>${question}<br/><strong>ç­”ï¼š</strong>${answer}`;
  historyList.prepend(li);
}

// ğŸ§  TTS language detection
function detectLang(text) {
  return /[\u4e00-\u9fa5]/.test(text) ? "zh-CN" : "en-GB";
}

function getVoiceForLang(lang) {
  const voices = speechSynthesis.getVoices();
  if (lang === "zh-CN") {
    return voices.find(v => v.lang === "zh-CN") || voices.find(v => v.name.includes("Google æ™®é€šè¯ å¥³å£°"));
  } else {
    return voices.find(v => v.lang === "en-GB") || voices.find(v => v.name.includes("Google UK English Female"));
  }
}

function speakMixed(text) {
  const segments = text.split(/(?<=[ã€‚.!?])/);
  segments.forEach(segment => {
    const trimmed = segment.trim();
    if (trimmed) {
      const lang = detectLang(trimmed);
      const utter = new SpeechSynthesisUtterance(trimmed);
      utter.lang = lang;
      utter.voice = getVoiceForLang(lang);
      utter.rate = 1;
      speechSynthesis.speak(utter);
    }
  });
}

function playTTS() {
  const english = responseBox.textContent.trim();
  const chinese = translationBox.textContent.replace(/^ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘ï¼š/, "").trim();
  speakMixed(`${english} ${chinese}`);
}

document.getElementById("ttsBtn")?.addEventListener("click", playTTS);

// ğŸ¤ Hold-to-speak mic input
if (window.SpeechRecognition || window.webkitSpeechRecognition) {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  recognition.lang = "zh-CN";
  recognition.continuous = false;
  recognition.interimResults = false;

  micBtn.addEventListener("mousedown", () => {
    recognition.start();
    micBtn.textContent = "ğŸ¤ æ­£åœ¨å½•éŸ³... (æ¾å¼€å‘é€)";
  });

  micBtn.addEventListener("mouseup", () => {
    recognition.stop();
    micBtn.textContent = "ğŸ¤ è¯­éŸ³æé—®";
  });

  micBtn.addEventListener("touchstart", () => {
    recognition.start();
    micBtn.textContent = "ğŸ¤ æ­£åœ¨å½•éŸ³... (æ¾å¼€å‘é€)";
  });

  micBtn.addEventListener("touchend", () => {
    recognition.stop();
    micBtn.textContent = "ğŸ¤ è¯­éŸ³æé—®";
  });

  recognition.onresult = (event) => {
    const spoken = event.results[0][0].transcript;
    questionInput.value = spoken;
    submitQuestion();
  };

  recognition.onerror = (event) => {
    alert("ğŸ¤ æ— æ³•è¯†åˆ«è¯­éŸ³ï¼Œè¯·é‡è¯•ã€‚");
    console.error("SpeechRecognition error:", event.error);
  };
}

// ğŸŒ Expose to window
window.submitQuestion = submitQuestion;
window.setExam = setExam;
